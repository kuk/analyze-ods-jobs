
# Натекин

Запостю тогда сперва список гипотез на основе (грядущих) данных
вакансий, с постепенно-нарастающим использованием их структуры. то
есть, на начальных уровнях айсберга нужно мало вытащенной инфы из
вакансий, а потом становится все глубже и интимнее:

1. Банальная аналитика: нарисовать во времени распределения зп по
   вакансиям в разрезе 5-7 лет. эдакие удавы, съевшие слонов и как эти
   распределения менялись во времени (подгипотеза: этот быстрее
   инфляции или нет? как он менялся между годами?). как отличаются зп
   между городами и странами?  всмысле, как графически (визуализации),
   так и по какой формуле? простая гипотеза вида salary_spb =
   a_spb*salary_moscow + b_spb, какие тогда a и b между городами и
   странами? а если распарсить данные чуть глубже (типа из какой
   отрасли вакансия - телеком/банки/...), можно и по компаниям и их
   запросам тоже сделать аналитику (заодно проверить гипотезу, что с
   приходом удаленки стали меньше искать джунов, и сильно больше
   синьоров?).

2. модельная аналитика типов вакансий. если есть названия вакансий,
   плюс (самое главное) в каком-то виде тэги из них, то можно сделать
   простой логрег на типы вакансий. например, что реально по данным
   отличает DS от DA, MLE, DS менеджеров, и т.д. Можно просто анализом
   коэффициентов (в предположении что из тегов предиктится сколь
   угодно сносно). Задача со звездочкой - для тех, кто умеет
   моделировать во времени (например с регрессионными фильтрами) -
   посмотреть, как эти коэффициенты менялись во времени (бонус -
   тематические гипотезы вида в какой момент реально умер R). ну или
   тем, кто еще не умеет - предиктить job_type*year (хоть это и
   размоет значимость/используемые данные на коэффициент ибо моделей
   будет столько же). для совсем начинающих - максимально неправильная
   идея пытаться зафитить тяжеловесную модель на такие данные
   :легкая_улыбка: логрег, одинарные деревья, максимум - деревянные
   фичи (сплиты), добавленные. в логрег

3. едем дальше - если у нас ещё и целевая переменная в виде условной
   середины вилки (это можно обсуждать), да еще и в придачу к ней
   всякие допы (level ~ intern/jun/mid/...; country/city ...), то
   можно строить еще более веселые модельные гипотезы. например
   оценивать вклад тегов вакансии (которых можно считать эдаким
   наличием конкретной экспы/конкретных скиллов, и т.д.) в зп: знанием
   spark докидывает зп всюду, а знание tf в конкретных вакансиях
   (продолжая пункт 2, можно ещё в разрезе лет смотреть штуки вида
   "когда соревнования докидывали больше всего, а когда стали
   неинформативны?") . или какие теги/... (число лет работы? или еще
   куча sparse вещей) воспринимаются авторами важными лычками для
   перехода на следующий уровень?

4. следующий уровень - когда есть всё, и можно ещё как-то с эмоджами
   это матчить. например, насколько сильно разные эмоджи зависят от
   угадывания/не угадывания эдакого сферического_рыночного_среднего
   для аналогичных вакансий в моменте? являются ли вообще эмоджи
   сколь-нибудь информативными фичами для свойств вакансий? например
   это может быть корреляция их числа с технологиями, с компаниями,
   городами, или авторами вакансий?

5. более персональный уровень - как вообще связаны эмоджи и люди,
   которые их ставят вакансиям? нет ли конкретных клик людей, которые
   ставят конкретные эмоджи конкретным типам вакансий? (можно тогда
   крафтить эдакий honeypot, с вакансиями которые бы зацепили именно
   этих людей). у какого числа людей и/или компаний имеются свои
   клики/фанклубы/хейтеры?

6. глубины айсберга вакансий одс - гипотеза о переобувании, а также в
   целом поведении людей, которые доросли до момента авторства
   вакансий к себе. изначально звучала как "найти вакансии и людей,
   которые сперва всем ставили лапшу, а потом сами стали постить то,
   чему бы сами постили лапшу и за что срались бы в треде"

# Разработка

python3.9
